# Our Description
Building a model with transfer learning for classifying speech conditions, specifically identifying speech delays (Dysarthria and Speech Language Impairment) from healthy speech. Involves downloading and organizing a labeled audio dataset from Google Drive. Each audio file is processed to extract waveforms and missing or corrupted files are filtered out. YAMNet, a deep learning model pre-trained on audio data and available on TensorFlow Hub, is utilized for feature extraction. YAMnet generates embeddings from audio files, which are used as the input to the neural networks. A neural network is built with multiple dense layers, L2 regularization, and dropout layers to prevent overfitting. Early stopping is used during training to avoid excessive epochs. The model is trained with binary cross-entropy loss and evaluated on accuracy, precision, recall, and confusion matrix metrics.
