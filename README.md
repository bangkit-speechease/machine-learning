# Our Description
Building a model with transfer learning for classifying speech conditions, specifically identifying speech delays (Dysarthria and Speech Language Impairment) from healthy speech. Involves downloading and organizing a collected audio dataset from Google Drive. Each audio file is processed to extract waveforms and missing or corrupted files are filtered out. YAMNet, a deep learning model from Tensorflow Hub, pre-trained on audio data for feature extraction. YAMnet generates embeddings from audio files, which are used as the input to the model. A model is built with hidden layers, dropout layers, and an output layer. Early stopping is used during training to avoid excessive epochs. The model is trained with binary cross-entropy loss and evaluated on accuracy, precision, recall, and confusion matrix metrics. The model achieved  an accuracy of 0.9147 and a validation accuracy of 0.9151.
